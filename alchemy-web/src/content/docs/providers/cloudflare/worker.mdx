---
title: Worker
description: Learn how to deploy, configure, and manage Cloudflare Workers using Alchemy for serverless functions at the edge.
---

A [Cloudflare Worker](https://developers.cloudflare.com/workers/) is a serverless function that runs on Cloudflare's global network.

## Quick Start

Deploy a minimal Worker with a single HTTP handler:

```ts
import { Worker } from "alchemy/cloudflare";

export const worker = await Worker("api", {
  name: "api-worker",
  entrypoint: "./src/api.ts",
});
```

The simplest possible Worker is just a function that returns a `Response`:

```ts
// ./src/api.ts
export default {
  async fetch(request: Request): Promise<Response> {
    return new Response("OK");
  },
};
```

:::tip
Start with a simple Worker like this to verify your deployment pipeline works, then gradually add complexity. Use the local development server to test changes quickly.
:::

## Handle Requests (common tasks)

Implement HTTP handlers for API endpoints, static content, and dynamic responses with proper error handling:
```ts
// ./src/api.ts
export default {
  async fetch(request: Request): Promise<Response> {
    const url = new URL(request.url);
    const path = url.pathname;
    
    try {
      // Route-based handling
      switch (path) {
        case "/api/users":
          return await handleUsers(request);
        case "/api/health":
          return new Response(JSON.stringify({ status: "ok", timestamp: Date.now() }), {
            headers: { "content-type": "application/json" }
          });
        default:
          return new Response("Not Found", { status: 404 });
      }
    } catch (error) {
      return new Response(JSON.stringify({ error: "Internal Server Error" }), {
        status: 500,
        headers: { "content-type": "application/json" }
      });
    }
  }
};

async function handleUsers(request: Request): Promise<Response> {
  if (request.method === "POST") {
    const userData = await request.json();
    // Process user data
    return new Response(JSON.stringify({ id: "123", ...userData }), {
      status: 201,
      headers: { "content-type": "application/json" }
    });
  }
  
  // GET request - return users list
  return new Response(JSON.stringify({ users: [] }), {
    headers: { "content-type": "application/json" }
  });
}
```

**Common patterns:**
- **REST APIs**: Handle GET/POST/PUT/DELETE methods
- **Webhooks**: Process incoming webhook payloads
- **Proxies**: Forward requests to backend services
- **Static serving**: Serve HTML, CSS, JS files

## Durable Objects

Durable Objects enable stateful serverless applications with coordination capabilities.

Create a `DurableObjectNamespace` in your `alchemy.run.ts` script and bind it to your Worker:

```ts
// alchemy.run.ts
import { Worker, DurableObjectNamespace } from "alchemy/cloudflare";

const counter = DurableObjectNamespace("counter", {
  className: "Counter",
  sqlite: true, // Enable SQLite storage
});

export const worker = await Worker("api", {
  entrypoint: "./src/worker.ts",
  bindings: {
    COUNTER: counter,
  }
});
```

Then export a class that extends `DurableObject` and has `"Counter"` as the class name to match the `DurableObjectNamespace` you created:

```ts
// ./src/worker.ts
import { DurableObject } from "cloudflare:workers";

export class Counter extends DurableObject {
  async increment(): Promise<number> {
    let count = (await this.ctx.storage.get("count")) || 0;
    count++;
    await this.ctx.storage.put("count", count);
    return count;
  }

  async fetch(request: Request): Promise<Response> {
    const count = await this.increment();
    return Response.json({ count });
  }
}
```

Finally, in your `fetch` handler, you can get a Durable Object instance via the `COUNTER` binding:

```ts
export default {
  async fetch(request: Request, env: typeof worker.Env) {
    const id = env.COUNTER.idFromName("global-counter");
    const obj = env.COUNTER.get(id);
    return obj.fetch(request);
  }
}
```

:::tip[Durable Objects Guide]
For comprehensive Durable Objects documentation including WebSocket integration, alarms, and advanced patterns, see the [Durable Object Namespace guide](/providers/cloudflare/durable-object-namespace).
:::

## Bindings & Types (access external resources)

Use bindings to attach KV, R2, Durable Objects, secrets, and other resources to the Worker. 
Configure Worker properties for compatibility, observability, and runtime limits:
```ts
// alchemy.run.ts
import alchemy from 'alchemy';
import { Worker, KVNamespace, R2Bucket } from "alchemy/cloudflare";

const cache = await KVNamespace("cache", { title: "cache-store" });
const storage = await R2Bucket("storage", { name: "user-storage" });

export const worker = await Worker("api", {
  name: "api-worker",                     // Worker name (defaults to ${app}-${stage}-${id})
  url: true,                              // Enable workers.dev preview URL (defaults to false; created unless using a dispatch namespace)
  cwd: "./apps/my-api",                   // Project root directory (defaults to process.cwd())
  entrypoint: "./src/api.ts",             // Main entrypoint for bundling
  format: "esm",                          // Module format: 'esm' (default) or 'cjs'
  // compatibilityDate defaults to the SDK's pinned date; override only when you need a specific runtime
  compatibilityDate: "2025-09-13",        // Workers runtime version (uses DEFAULT_COMPATIBILITY_DATE when omitted)
  compatibilityFlags: ["nodejs_compat"],  // Low-level runtime flags; consider using `compatibility` preset instead
  compatibility: "node",                  // Compatibility preset (optional) — expands flags for common use-cases like Node.js compatibility
  adopt: true,                            // Adopt existing Worker if present; falls back to scope.adopt when undefined
  bindings: {
    CACHE: cache,                         // KV Namespace binding
    STORAGE: storage,                     // R2 bucket binding
    API_KEY: alchemy.secret("secret-value") // Plain-text env binding (converted to plain_text)
    // Other binding types include: DurableObjectNamespace, Queue, Secret, Assets, Container, Workflow
  },
  observability: {
    enabled: true                         // Enable worker logs / observability (default: true)
  },
  // Upload source maps to improve stack traces (set to false to disable)
  sourceMap: true,
  // Optional runtime limits — increase only when necessary after monitoring
  limits: {
    cpu_ms: 50_000                        // Max CPU time in ms (default: 30_000)
  },
  // Other Advanced 🧪 & commonly used options
  placement: { mode: "smart" },          // Smart placement to optimize network placement for latency
  assets: { path: "./public", run_worker_first: false }, // Static assets configuration
  crons: ["0 0 * * *"],                  // Scheduled cron triggers (standard cron syntax)
  eventSources: [                        // Background event sources (queues, streams)
    { queue: taskQueue, settings: { batchSize: 15, maxConcurrency: 3 } }
  ],
  routes: ["api.example.com/*"],          // Route patterns to bind the worker
  domains: ["example.com"],               // Custom domains to bind (can be objects with zoneId/adopt)
  version: "pr-123",                      // Publish as preview version with label
  dev: {
    port: 8787, // Hard-code the port used by the local worker development server (default: one is derived)
    tunnel: true, // Create a Cloudflare Tunnel and proxy requests to the local development server (default: false)
    remote: true, // Run the worker in Cloudflare instead of locally (default: false)
  },                    
  // Deploy to dispatch namespace (string | DispatchNamespace)
  namespace: await DispatchNamespace("my-dispatch-ns", {
    namespace: "production-dispatch"
  }),                    
  noBundle: true,                         // Disable bundling (default: false)
  rules: [{ globs: ["**/*.wasm"] }],      // Additional bundle rules
});
```

:::tip
Monitor your CPU usage with Cloudflare Analytics to understand if increased limits are necessary. Start with default limits and scale up only when needed to optimize costs.
:::


Initialize clients at the top-level of your Worker script:
```ts
// src/worker.ts
import { env } from "cloudflare:workers";
import ApiClient from "example-api-client";

// Initialize client at module scope
const apiClient = new ApiClient();

export default {
  async fetch(request: Request, env: Env) {
    // Configure with API key during request handling
    apiClient.setApiKey(env.API_KEY);
    return new Response("Configured with API key");
  },
};
```


:::tip
Initializing clients at top-level can reduce cold start times because the Worker isolate is pre-warmed during the first request handshake.
:::

:::caution
I/O is not allowed at top-level in Cloudflare Workers.
:::


## Infer Environment Types (recommended):
Alchemy doesn't use code-generation. Instead, your Worker's environment types can be inferred from the infrastructure configuration in your `alchemy.run.ts` script.

There are two ways to infer the environment types:

#### 1. Specify the type of `env` in your worker (simplest):
```ts
// src/worker.ts
import type { worker } from "../alchemy.run.ts";

export default {
  async fetch(request, env: typeof worker.Env) {
    await env.CACHE.get("key");
  },
};
```

#### 2. Cast `env` from the `cloudflare:workers` module:

If you need access to the env at the top level, create a file called `env.ts` re-export `env` casted to the worker's environment type:
```ts 
// ./src/env.ts
import { env } from "cloudflare:workers";

export type Env = typeof Env;
export const Env = env as typeof worker.Env;
```

Then import and use the `Env` type in your worker and initialize your clients, etc.
```ts
// src/worker.ts
import { Env } from "./env.ts";

const myClient = new MyClient(Env.DB);
```

## Queue Processing (event-driven Workers)

Configure Workers to consume messages from queues with automatic retries, batching, and dead letter queues for reliable background processing:
```ts
import { Worker, Queue } from "alchemy/cloudflare";

const taskQueue = await Queue("task-queue", {
  name: "task-processing"
});

const failedQueue = await Queue("failed-tasks", {
  name: "failed-tasks"
});

export const processor = await Worker("processor", {
  entrypoint: "./src/processor.ts",
  bindings: {
    TASK_QUEUE: taskQueue  // Producer - bind queue for sending messages
  },
  eventSources: [{  // Consumer - configure processing settings
    queue: taskQueue,
    settings: {
      batchSize: 15,           
      maxConcurrency: 3,       
      maxRetries: 5,           
      maxWaitTimeMs: 2500,     
      retryDelay: 60,          
      deadLetterQueue: failedQueue  
    }
  }]
});
```

**Queue Consumer Settings:**

| Setting | Purpose | Default | Example |
|---------|---------|---------|----------|
| `batchSize` | Messages processed per batch | 10 | `15` |
| `maxConcurrency` | Concurrent Worker invocations | 2 | `3` |
| `maxRetries` | Retry attempts for failed messages | 3 | `5` |
| `maxWaitTimeMs` | Max wait time to fill a batch | 500 | `2500` |
| `retryDelay` | Delay between retries (seconds) | 30 | `120` |
| `deadLetterQueue` | Queue for permanently failed messages | undefined | `failedQueue` |

:::tip
Tune queue settings based on your workload: increase `batchSize` for high-throughput processing, adjust `maxRetries` based on failure tolerance, and always configure a `deadLetterQueue` for debugging failed messages.
:::

**Consumer implementation:**
```ts
// ./src/processor.ts
import type { MessageBatch } from "@cloudflare/workers-types";

export default {
  async queue(batch: MessageBatch, env: Env) {
    for (const message of batch.messages) {
      try {
        const data = message.body;
        await processTask(data);
        message.ack(); // Acknowledge successful processing
      } catch (error) {
        message.retry(); // Retry on failure - respects maxRetries
      }
    }
  }
};
```

**When to use:** Background job processing, webhook handling, email processing, image optimization, data synchronization.

## Local development & configuration

Mirror production bindings in emulation, schedule tasks with cron, and serve static assets:

```ts
// alchemy.run.ts
await Worker("api", { 
  entrypoint: "./src/api.ts", 
  dev: { port: 8787 } 
});
```

## Cron Triggers

Schedule tasks with cron expressions:

```ts
// alchemy.run.ts
export const cronWorker = await Worker("cron-tasks", {
  entrypoint: "./src/cron.ts",
  crons: [
    "0 0 * * *",     // Run daily at midnight UTC
    "0 */6 * * *",   // Run every 6 hours
    "0 12 * * MON"   // Run Mondays at noon UTC
  ]
});

// Static assets serving
const assets = await Assets({ path: "./public" });

export const frontend = await Worker("frontend", {
  entrypoint: "./src/worker.ts",
  bindings: { ASSETS: assets }
});
```

### Scheduled handler implementation

```ts
// ./src/cron.ts
import type { ScheduledEvent } from "@cloudflare/workers-types";

export default {
  async scheduled(event: ScheduledEvent, env: Env) {
    const cron = event.cron;
    
    switch (cron) {
      case "0 0 * * *":
        await dailyCleanup(env);
        break;
      case "0 */6 * * *":
        await syncData(env);
        break;
    }
  }
};
```

**Common cron patterns:**
- `"0 0 * * *"` - Daily at midnight UTC
- `"0 */12 * * *"` - Every 12 hours
- `"0 9 * * MON-FRI"` - Weekdays at 9 AM UTC
- `"*/15 * * * *"` - Every 15 minutes

## Smart Placement (performance optimization)

Enable automatic network optimization by configuring smart placement to reduce latency and improve performance:

```ts
// alchemy.run.ts
export const optimizedWorker = await Worker("api", {
  entrypoint: "./src/api.ts",
  placement: {
    mode: "smart"  // Automatically optimize placement for performance
  }
});
```

**Benefits:**
- ✅ Automatic network optimization based on performance metrics
- ✅ Reduced latency for global users
- ✅ No infrastructure management required
- ✅ Seamless scaling across Cloudflare's network

**When to use:** Global applications, latency-sensitive APIs, high-traffic workloads, applications with geographically distributed users.

:::note
You can learn more about [Smart Placement](https://developers.cloudflare.com/workers/configuration/smart-placement/) in the Cloudflare documentation.
:::

## Advanced patterns (Worker composition, RPC, Durable Objects)

Build distributed systems using Worker-to-Worker communication, RPC patterns, and Durable Object sharing:

## Self-Binding

Enable Workers to reference themselves:

```ts
// alchemy.run.ts
import { Worker, Self } from "alchemy/cloudflare";

export const service = await Worker("auth-service", {
  entrypoint: "./src/auth.ts",
  bindings: { SELF: Self }
});
```

## Circular Dependencies

Break circular dependencies with WorkerStub:

```ts
// alchemy.run.ts
import { Worker, WorkerStub } from "alchemy/cloudflare";

const authStub = WorkerStub("auth", { name: "auth-service" });

export const apiWorker = await Worker("api", {
  entrypoint: "./src/api.ts",
  bindings: { AUTH: authStub }
});

export const authWorker = await Worker("auth", {
  entrypoint: "./src/auth.ts",
  bindings: { API: apiWorker }
});
```

**Other alternatives:**
- **Event-driven communication** via Queues or Durable Objects
- **Shared state** using Durable Objects as coordination layer
- **API Gateway pattern** with unidirectional data flow

## Service Mesh Pattern

```ts
// alchemy.run.ts
// Gateway Worker coordinates requests
export const gateway = await Worker("gateway", {
  entrypoint: "./src/gateway.ts",
  bindings: {
    USER_SERVICE: userService,
    ORDER_SERVICE: orderService,
    PAYMENT_SERVICE: paymentService
  },
  routes: ["api.example.com/*"]
});

// Individual service Workers
const userService = await Worker("users", {
  entrypoint: "./src/users.ts",
  bindings: { AUTH: authWorker }
});

const orderService = await Worker("orders", {
  entrypoint: "./src/orders.ts", 
  bindings: { 
    USERS: userService,
    PAYMENTS: paymentService
  }
});
```

**Benefits:**
- ✅ Distributed system architecture
- ✅ Service isolation and independent scaling
- ✅ Fault tolerance and graceful degradation
- ✅ Clear separation of concerns

**RPC pattern with WorkerEntrypoint:**

If you're using Workers RPC, you can specify the `rpc` property on the worker to define its interface when inferring the environment types:

For example, say you have a RPC worker that exports a class extending `WorkerEntrypoint`:

```ts
// ./src/rpc.ts
import { WorkerEntrypoint } from "cloudflare:workers";

export default class MyRPC extends WorkerEntrypoint {
  async getData(id: string): Promise<{ id: string }> {
    return { id };
  }
}
```

If you don't specify the `rpc` property, the environment type will be inferred from the worker's entrypoint.
```ts
// src/worker.ts
export default {
  async fetch(request: Request, env: typeof worker.Env) {
    // ❌ Type error
    await env.getData("123");
  },
};
```


In your `alchemy.run.ts` script, import the `type MyRPC` and set it as the `rpc` property on the worker:

```diff lang='ts'
// alchemy.run.ts
import { Worker, type } from "alchemy/cloudflare";
import type MyRPC from "./src/rpc.ts";

export const rpcWorker = await Worker("rpc", {
  entrypoint: "./src/rpc.ts",
+  rpc: type<MyRPC>,
});
```

Now, when you access the `rpc` binding in your worker, it will have the correct types:

```ts
// src/worker.ts
export default {
  async fetch(request: Request, env: typeof rpcWorker.Env) {
    const result = await env.RPC.getData("123");
  },
};
```

## Access Durable Object from another Worker

You can access a Durable Object from another Worker by using the `bindings` property:

```diff lang='ts'
// alchemy.run.ts
import { Worker, DurableObjectNamespace } from "alchemy/cloudflare";

const data = await Worker("data", {
  entrypoint: "./src/data.ts",
  bindings: {
    STORAGE: DurableObjectNamespace("storage", { 
      className: "DataStorage" 
    }),
  },
});

await Worker("api", {
  entrypoint: "./src/api.ts",
  bindings: { 
+    // ✅ Access the STORAGE DO hosted in the `data` worker
+    STORAGE: data.bindings.STORAGE
  },
});
```

## Deploy, preview, and routing

Enable preview URLs for testing and configure production routing with domains and routes:

```ts
// alchemy.run.ts
// Preview Worker for testing
const preview = await Worker("preview", {
  name: "my-worker",
  entrypoint: "./src/worker.ts",
  version: "pr-123",
  url: true,
});

console.log(preview.url);
```

**When to use `url: true`**

- **Use for**: CI previews, demos, short-lived feature previews, and sharing a build with reviewers.  
- **Do not use for production**: Route production traffic via `domains` or `routes` to ensure DNS/TLS control and SLAs.  

Define routes and domains alongside the Worker to keep routing policies readable:
```ts
// alchemy.run.ts
import { Worker, Zone } from "alchemy/cloudflare";

const zone = await Zone("example", { name: "example.com", type: "full" });

export const api = await Worker("api", {
  entrypoint: "./src/api.ts",
  routes: [
    "backend.example.com/*",
    { pattern: "api.example.com/*", zoneId: zone.id },
  ],
  domains: ["admin.example.com"],
});
```

**When to use `url: true`:** CI previews, demos, short-lived feature previews. **Do not use for production** prefer `domains`/`routes` for DNS/TLS control.

:::caution
Preview URLs may be unavailable for Durable Objects or special bindings. See [Preview URL](https://developers.cloudflare.com/workers/configuration/previews/#limitations) for details.
:::

## Migrating from Wrangler to Alchemy
Generate `wrangler.json` is available with the `WranglerJson` resource:
```ts
// alchemy.run.ts
import { WranglerJson } from "alchemy/cloudflare";

await WranglerJson({
  worker: api,
  transform: {
    wrangler: (spec) => ({
      ...spec,
      vars: { ...spec.vars, CUSTOM_VAR: "value" },
    }),
  },
});
```

:::tip
Alchemy highly encourages you to codify your Worker configuration in your `alchemy.run.ts` script,
only generate wrangler.json when you need to integrate with existing Wrangler-based tooling or CI/CD pipelines. 
Alchemy's declarative approach eliminates the need for most wrangler.json configurations.
:::

## Troubleshooting (common issues)

**Binding Resolution Errors:** Ensure bindings are configured in Worker definition.
```ts
// alchemy.run.ts
// ✅ created a KV namespace
const cache = await KVNamespace("cache");

// ❌ but, forget to bind it to the worker
export const worker = await Worker("api");
```

```ts
// src/worker.ts
// ❌ Missing binding configuration
await env.CACHE.get("key"); // ReferenceError
```

```diff lang='ts'
// alchemy.run.ts
// ✅ Correctly configured
const cache = await KVNamespace("cache");
export const worker = await Worker("api", {
+  bindings: { CACHE: cache }
});
```

**Queue Consumer Failures:** Always acknowledge or retry messages.
```ts
// src/worker.ts
// ❌ Missing acknowledgment
export default {
  async queue(batch: MessageBatch) {
    for (const message of batch.messages) {
      await processTask(message.body);
      // Missing: message.ack() or message.retry()
    }
  }
};
```

```diff lang='ts'
// ✅ Proper message handling
export default {
  async queue(batch: MessageBatch) {
    for (const message of batch.messages) {
      try {
        await processTask(message.body);
+        message.ack();
      } catch (error) {
+        // not necessary, but use retry to set a delay
+        message.retry({ delaySeconds: 30 });
      }
    }
  }
};
```

**Preview URL Limitations:** Use routes/domains for Durable Objects and production traffic. See [Cloudflare Docs - Previews Limitations](https://developers.cloudflare.com/workers/configuration/previews/#limitations) for details.
**Performance Issues:** Enable smart placement, increase CPU limits, use global scope initialization, cache data in KV, minimize cold starts.

## Next steps

- Static Assets: See [Assets](/providers/cloudflare/assets)
- Durable Objects & RPC: See [Durable Object Namespace](/providers/cloudflare/durable-object-namespace)
- Deploy & routing: See [Route](/providers/cloudflare/route), [Custom Domain](/providers/cloudflare/custom-domain), and [Zone](/providers/cloudflare/zone)


